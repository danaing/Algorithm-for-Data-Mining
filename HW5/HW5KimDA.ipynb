{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "##### 0-1. Checking the working environment #####\n",
    "#################################################\n",
    "\n",
    "def mylib () :\n",
    "    import os as os\n",
    "    mylib = input('Write the location of the data file. : ')\n",
    "    os.chdir(mylib)\n",
    "    print('Working Directory is now ', os.getcwd())\n",
    "\n",
    "###########################################\n",
    "##### 0-2. importing dataset function #####\n",
    "###########################################    \n",
    "    \n",
    "def read() :\n",
    "    import pandas as pd\n",
    "    name = input(\"Enter the data file name (with extension name) : \")\n",
    "    fm = input(\"Select the data coding format(1='a b c' or 2='a,b,c'): \" )\n",
    "    if fm == '1':\n",
    "        form = \" \"\n",
    "    elif fm == '2':\n",
    "        form = \",\"\n",
    "    return pd.read_csv(name, sep=form, header=None)\n",
    "    print('Successfully read the data file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "##### 1. regressoin function #####\n",
    "##################################\n",
    "\n",
    "def regression():\n",
    "    \n",
    "    # import packages\n",
    "    import numpy as np\n",
    "    import numpy.linalg as lin\n",
    "    import pandas as pd\n",
    "    \n",
    "    # prompt user to enter the data information\n",
    "    data = read()\n",
    "    \n",
    "    # import data\n",
    "    response = data[num]\n",
    "    explanatory = data.drop(num, axis=1)\n",
    "    \n",
    "    # design matrix\n",
    "    n = data.shape[0]\n",
    "    p = data.shape[1]-1\n",
    "    one = pd.DataFrame(np.ones((n,1)))\n",
    "    I = np.eye(n)\n",
    "    X = pd.concat([pd.DataFrame(one),explanatory], axis=1)\n",
    "    Y = response\n",
    "    H = X.dot(lin.inv(X.T.dot(X))).dot(X.T)\n",
    "    H0 = one.dot(lin.inv(one.T.dot(one))).dot(one.T)\n",
    "    inv = lin.inv(X.T.dot(X))\n",
    "    b = inv.dot(X.T).dot(Y).round(3)\n",
    "\n",
    "    # multiple regression result\n",
    "    yhat = H.dot(Y).round(1)\n",
    "    SST = Y.T.dot(I-H0).dot(Y)\n",
    "    SSE = Y.T.dot(I-H).dot(Y)\n",
    "    Rsquare = round(1 - SSE/SST, 4)\n",
    "    MSE = round(SSE/(n-p), 4)\n",
    "\n",
    "    # output file name\n",
    "    outputname = input(\"Write the output file name you want to save (without extension name) : \")\n",
    "    outputname = outputname+'.txt'\n",
    "\n",
    "    # outport the result\n",
    "    with open(outputname,\"w\") as text_file:\n",
    "        \n",
    "        print(\"Coefficients\", file=text_file)\n",
    "        print(\"-------------\", file=text_file)\n",
    "        for i in range(p+1):\n",
    "            if i==0:\n",
    "                print(\"Constant:\", b[i],sep=\"   \", file=text_file)\n",
    "            else: \n",
    "                print(\"Beta\",i,\":   \",b[i],sep=\"\", file=text_file)\n",
    "        print(\"\",file=text_file)\n",
    "\n",
    "        print(\"ID, Actual values, Fitted values\", file=text_file)\n",
    "        print(\"--------------------------------\", file=text_file)\n",
    "        for i in range(n):\n",
    "            print(i+1, Y[i], yhat[i], sep=\", \", file=text_file)\n",
    "        print(\"\",file=text_file)\n",
    "        \n",
    "        print(\"Model Summary\", file=text_file)\n",
    "        print(\"-------------\", file=text_file)\n",
    "        print(\"R-square = \", Rsquare, sep=\"\", file=text_file)\n",
    "        print(\"MSE = \", MSE, sep=\"\", file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "##### 2. Discrimant analysis function #####\n",
    "###########################################\n",
    "\n",
    "def discrimant_analysis() :\n",
    "    # import packages\n",
    "    import math\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from numpy.linalg import inv\n",
    "    from fractions import Fraction as frac\n",
    "    from pandas import DataFrame as df\n",
    "\n",
    "    ###################### General background #######################   \n",
    "    # Set priors and matrix for (i)LDA (ii)QDA (iii)RDA\n",
    "    if choice <= 3 :\n",
    "        print(' It has',k,'Classes.','\\n', \n",
    "              'Input each priors with ascending order of Class index.','\\n',\n",
    "              'ex) Priors of 3 class size = 1/3, 1/3, 1/3','\\n')\n",
    "        prior = input('Priors : ').split(',')\n",
    "        prior = list(map(lambda x: frac(x), prior))\n",
    "        if not len(prior) == k :\n",
    "            prior = [1/k]*k\n",
    "            print(\"Your prior input does not correscond with class size.\")\n",
    "            print(\"So equal prior is given such as\", prior)\n",
    "        elif not sum(prior)==1 :\n",
    "            prior = [1/k]*k\n",
    "            print(\"Sum of your prior input is not equal to 1.\")\n",
    "            print(\"So equal prior is given such as\", prior)\n",
    "\n",
    "        # Basic matrixs\n",
    "        n = train.shape[0]\n",
    "        nk = train[num].groupby(train[num]).count()\n",
    "        n_t = test.shape[0]\n",
    "        x = train.drop(num, axis=1).T\n",
    "        x_t = test.drop(num, axis=1).T\n",
    "        y = train[num]\n",
    "        y_t = test[num]\n",
    "        c = []\n",
    "        c_t = []\n",
    "        p = train.shape[1]-1\n",
    "        means = train.groupby(train[num]).mean().T\n",
    "        sk = train.groupby(train[num]).cov()\n",
    "        sp = 0\n",
    "\n",
    "        for i in range(1, k+1):\n",
    "            sp = sp + (nk[i]-1)*sk.loc[i]/(n-k)\n",
    "\n",
    "    ###############\n",
    "    ### (i) LDA ###\n",
    "    ###############\n",
    "    \n",
    "    if choice == 1 :\n",
    "        # Training data\n",
    "        d = (means.T).dot(inv(sp)).dot(x) + np.array(np.repeat(np.diag((-0.5)*means.T.dot(inv(sp)).dot(means)), n)).reshape(4,n) + np.repeat(np.log(prior),n).reshape(4,n) \n",
    "        c = df(d).idxmax()\n",
    "\n",
    "         # Test data\n",
    "        d_t = (means.T).dot(inv(sp)).dot(x_t) + np.array(np.repeat(np.diag((-0.5)*means.T.dot(inv(sp)).dot(means)), n_t)).reshape(4,n_t) + np.repeat(np.log(prior),n_t).reshape(4,n_t) \n",
    "        c_t = df(d_t).idxmax()\n",
    "\n",
    "    ################\n",
    "    ### (ii) QDA ###\n",
    "    ################\n",
    "    \n",
    "    if choice == 2 :\n",
    "        # (ii) QDA\n",
    "        # Training data\n",
    "        d = np.zeros((k,n))\n",
    "        for i in range(1, k+1):\n",
    "            d[i-1] = np.repeat((-0.5)*np.log(lin.det(sk.loc[i])),n) + np.diag((-0.5)*(x.apply(lambda x : x-means[i])).T.dot(inv(sk.loc[i])).dot(x.apply(lambda x : x-means[1]))) + np.repeat(np.log(prior[i-1]),n) \n",
    "        c = df(d, index=yclass).idxmax()\n",
    "\n",
    "        # Test data\n",
    "        d_t = np.zeros((k,n_t))\n",
    "        for i in range(1, k+1):\n",
    "            d_t[i-1] = np.repeat((-0.5)*np.log(lin.det(sk.loc[i])),n_t) + np.diag((-0.5)*(x_t.apply(lambda x : x-means[i])).T.dot(inv(sk.loc[i])).dot(x_t.apply(lambda x : x-means[1]))) + np.repeat(np.log(prior[i-1]),n_t) \n",
    "        c_t = df(d_t, index=yclass).idxmax()\n",
    "\n",
    "    #################\n",
    "    ### (iii) RDA ###\n",
    "    #################\n",
    "        \n",
    "    if choice == 3 :\n",
    "        #Alpha & gamma selection by 0.05\n",
    "        alpha = np.arange(0, 1.05, 0.05)\n",
    "        gamma = np.arange(0, 1.05, 0.05)\n",
    "        d_temp = np.zeros((k, n))\n",
    "        s_rda = np.zeros((p,p))\n",
    "        sigma = np.diag(sp).mean()\n",
    "        result = []\n",
    "\n",
    "        for a in alpha :\n",
    "            for g in gamma :\n",
    "                for i in yclass :\n",
    "                    s_rda = a*sk.loc[i] + (1-a)*(g*sp+(1-g)*sigma*np.eye(p))\n",
    "                    d_temp[i-1] = np.repeat((-0.5)*np.log(lin.det(s_rda)),n) + np.diag((-0.5)*(x.apply(lambda x : x-means[i])).T.dot(inv(s_rda)).dot(x.apply(lambda x : x-means[i]))) + np.repeat(np.log(prior[i-1]),n) \n",
    "                c_temp = df(d_temp, index=yclass).idxmax()\n",
    "                accuracy_temp = sum(c_temp==y)/n\n",
    "                accuracy_rate = [a,g, accuracy_temp]\n",
    "                result.append(accuracy_rate)\n",
    "\n",
    "            result = df(result, index=range(1, len(result)+1), columns=['alpha', 'gamma', 'accuracy rate'])\n",
    "\n",
    "        # Accuracy plot\n",
    "        import matplotlib.pyplot as plt\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        xss, yss = np.meshgrid(alpha,gamma)\n",
    "        z = np.array(result['accuracy rate'])\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(xss, yss, z, s=10, c='r')\n",
    "        ax.set_xlabel('Alpha')\n",
    "        ax.set_ylabel('Gamma')\n",
    "        ax.set_zlabel('Accuracy rate')\n",
    "        plt.show()\n",
    "\n",
    "        # Optimal parameters\n",
    "        optimal_loc = result['accuracy rate'].idxmax()\n",
    "        optimal = df(result.loc[optimal_loc])\n",
    "\n",
    "        print('Optimal parameters are given as follows.', '\\n')\n",
    "        print(optimal)\n",
    "        a = int(optimal.loc['alpha'])\n",
    "        g = int(optimal.loc['gamma'])\n",
    "\n",
    "        # Training data\n",
    "        d = np.zeros((k,n))\n",
    "        for i in yclass :\n",
    "            s_rda_op = a*sk.loc[i] + (1-a)*(g*sp + (1-g)*sigma*np.eye(p))\n",
    "            d[i-1] =  np.repeat((-0.5)*np.log(lin.det(s_rda_op)),n) + np.diag((-0.5)*(x.apply(lambda x : x-means[i])).T.dot(lin.inv(s_rda_op)).dot(x.apply(lambda x : x-means[i]))) + np.repeat(np.log(prior[i-1]),n) \n",
    "        c = df(d, index=yclass).idxmax()\n",
    "\n",
    "        # Test data\n",
    "        d_t = np.zeros((k,n_t))\n",
    "        for i in range(1, k+1):\n",
    "            s_rda_op = a*sk.loc[i] + (1-a)*(g*sp+(1-g)*sigma*np.eye(p))\n",
    "            d_t[i-1] =  np.repeat((-0.5)*np.log(lin.det(s_rda_op)),n_t) + np.diag((-0.5)*(x_t.apply(lambda x : x-means[i])).T.dot(lin.inv(s_rda_op)).dot(x_t.apply(lambda x : x-means[i]))) + np.repeat(np.log(prior[i-1]),n_t) \n",
    "        c_t = df(d_t, index=yclass).idxmax()\n",
    "\n",
    "    #######################################\n",
    "    ### Output setting for (i)(ii)(iii) ###\n",
    "    #######################################\n",
    "    \n",
    "    print('Please enter the number of the rows you can have.','\\n')\n",
    "    out_num = int(input('Enter the number : '))\n",
    "\n",
    "    # Crosstable\n",
    "    con = df({'Actual Class':y, 'Predicted Class':c})\n",
    "    table = pd.crosstab(con['Actual Class'],con['Predicted Class'], colnames=[''])\n",
    "    accuracy = np.trace(table)/n\n",
    "\n",
    "    con_t = df({'Actual Class':y_t, 'Predicted Class':c_t})\n",
    "    table_t = pd.crosstab(con_t['Actual Class'],con_t['Predicted Class'], colnames=[''])\n",
    "    accuracy_t = np.trace(table_t)/n_t\n",
    "\n",
    "    # output file\n",
    "    outputname = input(\"Write the output file name you want to save (without extension name) : \")\n",
    "    outputname = outputname+'.txt'\n",
    "\n",
    "    with open(outputname,\"w\") as text_file:\n",
    "\n",
    "        print('ID, Actual class, Resub pred', file=text_file)\n",
    "        print('-----------------------------', file=text_file)\n",
    "        for i in range(0, out_num):\n",
    "             print(i+1, y[i], c[i], sep=', ', file=text_file)\n",
    "        print('(continue)',file=text_file)        \n",
    "        print('',file=text_file)\n",
    "        print('Confusion Matrix (Resubstitution)', file=text_file)\n",
    "        print('----------------------------------','\\n','             Predicted Class', file=text_file)\n",
    "        print(table, file=text_file)\n",
    "        print(\"\",file=text_file)\n",
    "        print(\"Model Summary (Resubstitution)\", file=text_file)\n",
    "        print('------------------------------', file=text_file)\n",
    "        print(\"Overall accuracy = \", accuracy.round(3), sep='', file=text_file)\n",
    "        print('', file=text_file)\n",
    "\n",
    "        print('ID, Actual class, Test pred', file=text_file)\n",
    "        print('-----------------------------', file=text_file)\n",
    "        for i in range(0, out_num):\n",
    "            print(i+1, y_t[i], c_t[i], sep=', ', file=text_file)\n",
    "        print('(continue)',file=text_file)        \n",
    "        print('',file=text_file)\n",
    "        print('Confusion Matrix (Test)', file=text_file)\n",
    "        print('----------------------------------','\\n','             Predicted Class', file=text_file)\n",
    "        print(table_t, file=text_file)\n",
    "        print(\"\",file=text_file)\n",
    "        print(\"Model Summary (Test)\", file=text_file)\n",
    "        print('------------------------------', file=text_file)\n",
    "        print(\"Overall accuracy = \", accuracy_t.round(3), sep='', file=text_file)\n",
    "        print('', file=text_file)\n",
    "    print(\"Output file has been successfully saved in \",os.getcwd(),\"/\",outputname,sep=\"\") \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################\n",
    "### 3. Logistic Regression ###\n",
    "################################\n",
    "\n",
    "def logistic_regression() :\n",
    "    # import packages\n",
    "    import math\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from pandas import DataFrame as df\n",
    "    from scipy.optimize import minimize\n",
    "    \n",
    "    print('Importing TRAINING dataset')\n",
    "    train = read()\n",
    "    print('Importing TEST dataset')\n",
    "    test = read()\n",
    "    num = int(input(\"Enter which column the response variable is recorded: \"))-1\n",
    "\n",
    "    yclass = train[num].unique()\n",
    "    k = len(yclass) # Assume that values of the class variable are integers starting with 1\n",
    "    \n",
    "    # Basic matrix for Logistic\n",
    "    n = train.shape[0]\n",
    "    n_t = test.shape[0]\n",
    "    ex = train.drop(num, axis=1)\n",
    "    x = pd.concat([pd.DataFrame(np.repeat(1,n)),ex], axis=1)\n",
    "    ex_t = test.drop(num, axis=1)\n",
    "    x_t = pd.concat([pd.DataFrame(np.repeat(1,n_t)),ex_t], axis=1)\n",
    "    y = train[num]\n",
    "    y_t = test[num]\n",
    "    p = train.shape[1]\n",
    "    \n",
    "    def loglike(B):\n",
    "        return - np.dot((y-1).T,x).dot(B) + sum(np.log(1+np.exp(np.dot(x,B))))\n",
    "    loglik = minimize(loglike, np.repeat(0,p))\n",
    "    b = loglik.x\n",
    "    print('The result that maximizes Log-Likelihood of Logistic Regression(MLE method).')\n",
    "    print(df(b))\n",
    "    \n",
    "    cutoff = input('Enter the cutoff value from 0 to 1. : ')\n",
    "    cutoff = float(cutoff)\n",
    "    if not (0<=cutoff<=1) : \n",
    "        cutoff=0.5\n",
    "        print('The cutoff value must be in 0 to 1. So set 0.5 as the cutoff value.')\n",
    "        \n",
    "    # Training data\n",
    "    prob = np.round(np.exp(np.dot(x,b))/(1+np.exp(np.dot(x,b))), 3)\n",
    "    c = np.repeat(0,n)\n",
    "    c[prob >= cutoff]=2\n",
    "    c[prob <= cutoff]=1\n",
    "\n",
    "    # Test data\n",
    "    prob_t = np.round(np.exp(np.dot(x_t,b))/(1+np.exp(np.dot(x_t,b))), 3)\n",
    "    c_t = np.repeat(0,n_t)\n",
    "    c_t[prob_t >= cutoff]=2\n",
    "    c_t[prob_t <= cutoff]=1\n",
    "\n",
    "    # Output setting\n",
    "    out_num = int(input('Please enter the maximum output row you want to have in the output file. :' ))\n",
    "\n",
    "    # Crosstable\n",
    "    con = df({'Actual Class':y, 'Predicted Class':c})\n",
    "    table = pd.crosstab(con['Actual Class'],con['Predicted Class'], colnames=[''])\n",
    "    accuracy = np.trace(table)/n\n",
    "    sensi = table.loc[2,2]/sum(table.loc[2,])\n",
    "    speci = table.loc[1,1]/sum(table.loc[1,])\n",
    "\n",
    "    con_t = df({'Actual Class':y_t, 'Predicted Class':c_t})\n",
    "    table_t = pd.crosstab(con_t['Actual Class'],con_t['Predicted Class'], colnames=[''])\n",
    "    accuracy_t = np.trace(table_t)/n_t\n",
    "    sensi_t = table_t.loc[2,2]/sum(table_t.loc[2,])\n",
    "    speci_t = table_t.loc[1,1]/sum(table_t.loc[1,])\n",
    "\n",
    "    # output file\n",
    "    outputname = input(\"Write the output file name you want to save (without extension name) : \")\n",
    "    outputname = outputname+'.txt'\n",
    "\n",
    "    with open(outputname,\"w\") as text_file:\n",
    "\n",
    "        print('ID, Actual class, Resub pred, Pred Prob', file=text_file)\n",
    "        print('-----------------------------', file=text_file)\n",
    "        for i in range(0, out_num):\n",
    "             print(i+1, y[i], c[i], prob[i], sep=', ', file=text_file)\n",
    "        print('(continue)',file=text_file)        \n",
    "        print('',file=text_file)\n",
    "\n",
    "        print('Confusion Matrix (Resubstitution)', file=text_file)\n",
    "        print('----------------------------------','\\n','             Predicted Class', file=text_file)\n",
    "        print(table, file=text_file)\n",
    "        print(\"\",file=text_file)\n",
    "\n",
    "        print(\"Model Summary (Resubstitution)\", file=text_file)\n",
    "        print('------------------------------', file=text_file)\n",
    "        print(\"Overall accuracy = \", accuracy.round(3), sep='', file=text_file)\n",
    "        print(\"Sensitivity = \", sensi.round(3), sep='', file=text_file)\n",
    "        print(\"Specificity = \", speci.round(3), sep='', file=text_file)\n",
    "        print('', file=text_file)\n",
    "\n",
    "        print('ID, Actual class, Test pred, Pred Prob', file=text_file)\n",
    "        print('-----------------------------', file=text_file)\n",
    "        for i in range(0, out_num):\n",
    "            print(i+1, y_t[i], c_t[i], prob[i], sep=', ', file=text_file)\n",
    "        print('(continue)',file=text_file)        \n",
    "        print('',file=text_file)\n",
    "\n",
    "        print('Confusion Matrix (Test)', file=text_file)\n",
    "        print('----------------------------------','\\n','             Predicted Class', file=text_file)\n",
    "        print(table_t, file=text_file)\n",
    "        print(\"\",file=text_file)\n",
    "\n",
    "        print(\"Model Summary (Test)\", file=text_file)\n",
    "        print('------------------------------', file=text_file)\n",
    "        print(\"Overall accuracy = \", accuracy_t.round(3), sep='', file=text_file)\n",
    "        print(\"Sensitivity = \", sensi_t.round(3), sep='', file=text_file)\n",
    "        print(\"Specificity = \", speci_t.round(3), sep='', file=text_file)\n",
    "        print('', file=text_file)\n",
    "\n",
    "    print(\"Output file has been successfully saved in \",os.getcwd(),\"/\",outputname,sep=\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "##### 4. Combining the functions #####\n",
    "######################################\n",
    "\n",
    "def classification() :\n",
    "    print('Importing TRAINING dataset')\n",
    "    train = read()\n",
    "    print('Importing TEST dataset')\n",
    "    test = read()\n",
    "    num = int(input(\"Enter which column the response variable is recorded: \"))-1\n",
    "\n",
    "    yclass = train[num].unique()\n",
    "    k = len(yclass) # Assume that values of the class variable are integers starting with 1\n",
    "    \n",
    "    # choose (i)LDA (ii)QDA (iii)RDA (iv)Logistic Regression\n",
    "    choice = int(input(\"Enter 1 for LDA, 2 for QDA, 3 for RDA or 4 for Logistic Regression. : \"))\n",
    "\n",
    "    while (choice==4&k==2) :\n",
    "        choice = int(input(\"Enter 1 for LDA, 2 for QDA, 3 for RDA or 4 for Logistic Regression. : \"))\n",
    "        if (choice != 4) :\n",
    "            break   \n",
    "            \n",
    "    if choice <= 3 : \n",
    "        discriminant_analysis()\n",
    "    if choice == 4 : \n",
    "        logistic_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HW5() :\n",
    "    print('Checking the working environment.')\n",
    "    mylib()\n",
    "    ans = int(input('Enter 1 to use Regression, Enter 2 to use Classification : '))\n",
    "    if ans == 1 : \n",
    "        regression_analysis()\n",
    "    elif ans == 2 :\n",
    "        classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the working environment.\n",
      "Write the location of the data file. : C:/Users/User/Desktop/18-2/DM/data\n",
      "Working Directory is now  C:\\Users\\User\\Desktop\\18-2\\DM\\data\n",
      "Enter 1 to use Regression, Enter 2 to use Classification : 2\n",
      "Importing TRAINING dataset\n",
      "Enter the data file name (with extension name) : pid.dat\n",
      "Select the data coding format(1='a b c' or 2='a,b,c'): 2\n",
      "Importing TEST dataset\n",
      "Enter the data file name (with extension name) : pidtest.dat\n",
      "Select the data coding format(1='a b c' or 2='a,b,c'): 2\n",
      "Enter which column the response variable is recorded: 8\n",
      "Enter 1 for LDA, 2 for QDA, 3 for RDA or 4 for Logistic Regression. : 4\n",
      "Importing TRAINING dataset\n",
      "Enter the data file name (with extension name) : pid.dat\n",
      "Select the data coding format(1='a b c' or 2='a,b,c'): 2\n",
      "Importing TEST dataset\n",
      "Enter the data file name (with extension name) : pidtest.dat\n",
      "Select the data coding format(1='a b c' or 2='a,b,c'): 2\n",
      "Enter which column the response variable is recorded: 8\n",
      "The result that maximizes Log-Likelihood of Logistic Regression(MLE method).\n",
      "          0\n",
      "0  9.907715\n",
      "1 -0.201806\n",
      "2 -0.037412\n",
      "3  0.008598\n",
      "4 -0.013119\n",
      "5 -0.068822\n",
      "6 -1.805863\n",
      "7 -0.014290\n",
      "Enter the cutoff value from 0 to 1. : 0.5\n",
      "Please enter the maximum output row you want to have in the output file. :HW5KimDA_Logit_py_output\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'HW5KimDA_Logit_py_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-8c01f05f058a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mHW5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#C:/Users/User/Desktop/18-2/DM/data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-3e51091b30cb>\u001b[0m in \u001b[0;36mHW5\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mregression_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mans\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mclassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-60cca9461b08>\u001b[0m in \u001b[0;36mclassification\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mdiscriminant_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mlogistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-7f55f1fd1b9e>\u001b[0m in \u001b[0;36mlogistic_regression\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# Output setting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0mout_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Please enter the maximum output row you want to have in the output file. :'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# Crosstable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'HW5KimDA_Logit_py_output'"
     ]
    }
   ],
   "source": [
    "HW5() #C:/Users/User/Desktop/18-2/DM/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
