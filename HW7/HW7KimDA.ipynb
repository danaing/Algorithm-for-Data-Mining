{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "##### 0-1. Checking the working environment #####\n",
    "#################################################\n",
    "\n",
    "def mylib () :\n",
    "    import os as os\n",
    "    mylib = input('Write the location of the data file. : ')\n",
    "    os.chdir(mylib)\n",
    "    print('Working Directory is now ', os.getcwd())\n",
    "\n",
    "###########################################\n",
    "##### 0-2. importing dataset function #####\n",
    "###########################################    \n",
    "    \n",
    "def read() :\n",
    "    import pandas as pd\n",
    "    name = input(\"Enter the data file name (with extension name) : \")\n",
    "    fm = input(\"Select the data coding format(1='a b c' or 2='a,b,c'): \" )\n",
    "    if fm == '1':\n",
    "        form = \" \"\n",
    "    elif fm == '2':\n",
    "        form = \",\"\n",
    "    return pd.read_csv(name, sep=form, header=None)\n",
    "    print('Successfully read the data file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "##### 1. regressoin function #####\n",
    "##################################\n",
    "\n",
    "def regression():\n",
    "    # import packages\n",
    "    import numpy as np\n",
    "    import numpy.linalg as lin\n",
    "    import pandas as pd\n",
    "    \n",
    "    # prompt user to enter the data information\n",
    "    data = read()\n",
    "    \n",
    "    # import data\n",
    "    response = data[num]\n",
    "    explanatory = data.drop(num, axis=1)\n",
    "    \n",
    "    # design matrix\n",
    "    n = data.shape[0]\n",
    "    p = data.shape[1]-1\n",
    "    one = pd.DataFrame(np.ones((n,1)))\n",
    "    I = np.eye(n)\n",
    "    X = pd.concat([pd.DataFrame(one),explanatory], axis=1)\n",
    "    Y = response\n",
    "    H = X.dot(lin.inv(X.T.dot(X))).dot(X.T)\n",
    "    H0 = one.dot(lin.inv(one.T.dot(one))).dot(one.T)\n",
    "    inv = lin.inv(X.T.dot(X))\n",
    "    b = inv.dot(X.T).dot(Y).round(3)\n",
    "\n",
    "    # multiple regression result\n",
    "    yhat = H.dot(Y).round(1)\n",
    "    SST = Y.T.dot(I-H0).dot(Y)\n",
    "    SSE = Y.T.dot(I-H).dot(Y)\n",
    "    Rsquare = round(1 - SSE/SST, 4)\n",
    "    MSE = round(SSE/(n-p), 4)\n",
    "\n",
    "    # output file name\n",
    "    outputname = input(\"Write the output file name you want to save (without extension name) : \")\n",
    "    outputname = outputname+'.txt'\n",
    "\n",
    "    # outport the result\n",
    "    with open(outputname,\"w\") as text_file:\n",
    "        \n",
    "        print(\"Coefficients\", file=text_file)\n",
    "        print(\"-------------\", file=text_file)\n",
    "        for i in range(p+1):\n",
    "            if i==0:\n",
    "                print(\"Constant:\", b[i],sep=\"   \", file=text_file)\n",
    "            else: \n",
    "                print(\"Beta\",i,\":   \",b[i],sep=\"\", file=text_file)\n",
    "        print(\"\",file=text_file)\n",
    "\n",
    "        print(\"ID, Actual values, Fitted values\", file=text_file)\n",
    "        print(\"--------------------------------\", file=text_file)\n",
    "        for i in range(n):\n",
    "            print(i+1, Y[i], yhat[i], sep=\", \", file=text_file)\n",
    "        print(\"\",file=text_file)\n",
    "        \n",
    "        print(\"Model Summary\", file=text_file)\n",
    "        print(\"-------------\", file=text_file)\n",
    "        print(\"R-square = \", Rsquare, sep=\"\", file=text_file)\n",
    "        print(\"MSE = \", MSE, sep=\"\", file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "##### 2. Classification #####\n",
    "#############################\n",
    "\n",
    "def classification() :\n",
    "    # import packages\n",
    "    import os as os\n",
    "    import math\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from numpy.linalg import inv\n",
    "    from fractions import Fraction as frac\n",
    "    from pandas import DataFrame as df\n",
    "\n",
    "    ###################### General background #######################  \n",
    "    \n",
    "    # read data\n",
    "    print('Importing TRAINING dataset')\n",
    "    train = read()\n",
    "    print('Importing TEST dataset')\n",
    "    test = read()\n",
    "    num = int(input(\"Enter which column the response variable is recorded: \"))-1\n",
    "\n",
    "    yclass = train[num].unique()\n",
    "    k = len(yclass) # Assume that values of the class variable are integers starting with 1\n",
    "    \n",
    "    # method choice\n",
    "    choice = int(input(\"Enter 1 for LDA, 2 for QDA, 3 for RDA , 4 for Logistic Regression, 5 for Naive Bayes or 6 for 1-level decision tree. : \"))\n",
    "    #while ((choice==4&k!=2) | (choice==5$k!=2)) :\n",
    "    #    choice = int(input(\"Enter 1 for LDA, 2 for QDA, 3 for RDA , 4 for Logistic Regression or 5 for Naive Bayes. : \"))\n",
    "    #    if ((choice != 4)|(choice!=5)) :\n",
    "    #        break   \n",
    "    \n",
    "    \n",
    "    if choice <= 3 :\n",
    "        print(' It has',k,'Classes.','\\n', \n",
    "              'Input each priors with ascending order of Class index.','\\n',\n",
    "              'ex) Priors of 3 class size = 1/3, 1/3, 1/3','\\n')\n",
    "        prior = input('Priors : ').split(',')\n",
    "        prior = list(map(lambda x: frac(x), prior))\n",
    "        if not len(prior) == k :\n",
    "            prior = [1/k]*k\n",
    "            print(\"Your prior input does not correscond with class size.\")\n",
    "            print(\"So equal prior is given such as\", prior)\n",
    "        elif not sum(prior)==1 :\n",
    "            prior = [1/k]*k\n",
    "            print(\"Sum of your prior input is not equal to 1.\")\n",
    "            print(\"So equal prior is given such as\", prior)\n",
    "\n",
    "        # Basic matrixs\n",
    "        n = train.shape[0]\n",
    "        nk = train[num].groupby(train[num]).count()\n",
    "        n_t = test.shape[0]\n",
    "        x = train.drop(num, axis=1).T\n",
    "        x_t = test.drop(num, axis=1).T\n",
    "        y = train[num]\n",
    "        y_t = test[num]\n",
    "        c = []\n",
    "        c_t = []\n",
    "        p = train.shape[1]-1\n",
    "        means = train.groupby(train[num]).mean().T\n",
    "        sk = train.groupby(train[num]).cov()\n",
    "        sp = 0\n",
    "\n",
    "        for i in range(1, k+1):\n",
    "            sp = sp + (nk[i]-1)*sk.loc[i]/(n-k)\n",
    "\n",
    "    ###############\n",
    "    ### (i) LDA ###\n",
    "    ###############\n",
    "    \n",
    "    if choice == 1 :\n",
    "        # Training data\n",
    "        d = (means.T).dot(inv(sp)).dot(x) + np.array(np.repeat(np.diag((-0.5)*means.T.dot(inv(sp)).dot(means)), n)).reshape(4,n) + np.repeat(np.log(prior),n).reshape(4,n) \n",
    "        c = df(d).idxmax()\n",
    "\n",
    "         # Test data\n",
    "        d_t = (means.T).dot(inv(sp)).dot(x_t) + np.array(np.repeat(np.diag((-0.5)*means.T.dot(inv(sp)).dot(means)), n_t)).reshape(4,n_t) + np.repeat(np.log(prior),n_t).reshape(4,n_t) \n",
    "        c_t = df(d_t).idxmax()\n",
    "\n",
    "    ################\n",
    "    ### (ii) QDA ###\n",
    "    ################\n",
    "    \n",
    "    if choice == 2 :\n",
    "        # (ii) QDA\n",
    "        # Training data\n",
    "        d = np.zeros((k,n))\n",
    "        for i in range(1, k+1):\n",
    "            d[i-1] = np.repeat((-0.5)*np.log(lin.det(sk.loc[i])),n) + np.diag((-0.5)*(x.apply(lambda x : x-means[i])).T.dot(inv(sk.loc[i])).dot(x.apply(lambda x : x-means[1]))) + np.repeat(np.log(prior[i-1]),n) \n",
    "        c = df(d, index=yclass).idxmax()\n",
    "\n",
    "        # Test data\n",
    "        d_t = np.zeros((k,n_t))\n",
    "        for i in range(1, k+1):\n",
    "            d_t[i-1] = np.repeat((-0.5)*np.log(lin.det(sk.loc[i])),n_t) + np.diag((-0.5)*(x_t.apply(lambda x : x-means[i])).T.dot(inv(sk.loc[i])).dot(x_t.apply(lambda x : x-means[1]))) + np.repeat(np.log(prior[i-1]),n_t) \n",
    "        c_t = df(d_t, index=yclass).idxmax()\n",
    "\n",
    "    #################\n",
    "    ### (iii) RDA ###\n",
    "    #################\n",
    "        \n",
    "    if choice == 3 :\n",
    "        #Alpha & gamma selection by 0.05\n",
    "        alpha = np.arange(0, 1.05, 0.05)\n",
    "        gamma = np.arange(0, 1.05, 0.05)\n",
    "        d_temp = np.zeros((k, n))\n",
    "        s_rda = np.zeros((p,p))\n",
    "        sigma = np.diag(sp).mean()\n",
    "        result = []\n",
    "\n",
    "        for a in alpha :\n",
    "            for g in gamma :\n",
    "                for i in yclass :\n",
    "                    s_rda = a*sk.loc[i] + (1-a)*(g*sp+(1-g)*sigma*np.eye(p))\n",
    "                    d_temp[i-1] = np.repeat((-0.5)*np.log(lin.det(s_rda)),n) + np.diag((-0.5)*(x.apply(lambda x : x-means[i])).T.dot(inv(s_rda)).dot(x.apply(lambda x : x-means[i]))) + np.repeat(np.log(prior[i-1]),n) \n",
    "                c_temp = df(d_temp, index=yclass).idxmax()\n",
    "                accuracy_temp = sum(c_temp==y)/n\n",
    "                accuracy_rate = [a,g, accuracy_temp]\n",
    "                result.append(accuracy_rate)\n",
    "\n",
    "            result = df(result, index=range(1, len(result)+1), columns=['alpha', 'gamma', 'accuracy rate'])\n",
    "\n",
    "        # Accuracy plot\n",
    "        import matplotlib.pyplot as plt\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        xss, yss = np.meshgrid(alpha,gamma)\n",
    "        z = np.array(result['accuracy rate'])\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(xss, yss, z, s=10, c='r')\n",
    "        ax.set_xlabel('Alpha')\n",
    "        ax.set_ylabel('Gamma')\n",
    "        ax.set_zlabel('Accuracy rate')\n",
    "        plt.show()\n",
    "\n",
    "        # Optimal parameters\n",
    "        optimal_loc = result['accuracy rate'].idxmax()\n",
    "        optimal = df(result.loc[optimal_loc])\n",
    "\n",
    "        print('Optimal parameters are given as follows.', '\\n')\n",
    "        print(optimal)\n",
    "        a = int(optimal.loc['alpha'])\n",
    "        g = int(optimal.loc['gamma'])\n",
    "\n",
    "        # Training data\n",
    "        d = np.zeros((k,n))\n",
    "        for i in yclass :\n",
    "            s_rda_op = a*sk.loc[i] + (1-a)*(g*sp + (1-g)*sigma*np.eye(p))\n",
    "            d[i-1] =  np.repeat((-0.5)*np.log(lin.det(s_rda_op)),n) + np.diag((-0.5)*(x.apply(lambda x : x-means[i])).T.dot(lin.inv(s_rda_op)).dot(x.apply(lambda x : x-means[i]))) + np.repeat(np.log(prior[i-1]),n) \n",
    "        c = df(d, index=yclass).idxmax()\n",
    "\n",
    "        # Test data\n",
    "        d_t = np.zeros((k,n_t))\n",
    "        for i in range(1, k+1):\n",
    "            s_rda_op = a*sk.loc[i] + (1-a)*(g*sp+(1-g)*sigma*np.eye(p))\n",
    "            d_t[i-1] =  np.repeat((-0.5)*np.log(lin.det(s_rda_op)),n_t) + np.diag((-0.5)*(x_t.apply(lambda x : x-means[i])).T.dot(lin.inv(s_rda_op)).dot(x_t.apply(lambda x : x-means[i]))) + np.repeat(np.log(prior[i-1]),n_t) \n",
    "        c_t = df(d_t, index=yclass).idxmax()\n",
    "\n",
    "    #######################################\n",
    "    ### Output setting for (i)(ii)(iii) ###\n",
    "    #######################################\n",
    "    \n",
    "    if choice <= 3 :\n",
    "\n",
    "        print('Please enter the number of the rows you can have.','\\n')\n",
    "        out_num = int(input('Enter the number : '))\n",
    "\n",
    "        # Crosstable\n",
    "        con = df({'Actual Class':y, 'Predicted Class':c})\n",
    "        table = pd.crosstab(con['Actual Class'],con['Predicted Class'], colnames=[''])\n",
    "        accuracy = np.trace(table)/n\n",
    "\n",
    "        con_t = df({'Actual Class':y_t, 'Predicted Class':c_t})\n",
    "        table_t = pd.crosstab(con_t['Actual Class'],con_t['Predicted Class'], colnames=[''])\n",
    "        accuracy_t = np.trace(table_t)/n_t\n",
    "\n",
    "        # output file\n",
    "        outputname = input(\"Write the output file name you want to save (without extension name) : \")\n",
    "        outputname = outputname+'.txt'\n",
    "\n",
    "        with open(outputname,\"w\") as text_file:\n",
    "\n",
    "            print('ID, Actual class, Resub pred', file=text_file)\n",
    "            print('-----------------------------', file=text_file)\n",
    "            for i in range(0, out_num):\n",
    "                 print(i+1, y[i], c[i], sep=', ', file=text_file)\n",
    "            print('(continue)',file=text_file)        \n",
    "            print('',file=text_file)\n",
    "            print('Confusion Matrix (Resubstitution)', file=text_file)\n",
    "            print('----------------------------------','\\n','             Predicted Class', file=text_file)\n",
    "            print(table, file=text_file)\n",
    "            print(\"\",file=text_file)\n",
    "            print(\"Model Summary (Resubstitution)\", file=text_file)\n",
    "            print('------------------------------', file=text_file)\n",
    "            print(\"Overall accuracy = \", accuracy.round(3), sep='', file=text_file)\n",
    "            print('', file=text_file)\n",
    "\n",
    "            print('ID, Actual class, Test pred', file=text_file)\n",
    "            print('-----------------------------', file=text_file)\n",
    "            for i in range(0, out_num):\n",
    "                print(i+1, y_t[i], c_t[i], sep=', ', file=text_file)\n",
    "            print('(continue)',file=text_file)        \n",
    "            print('',file=text_file)\n",
    "            print('Confusion Matrix (Test)', file=text_file)\n",
    "            print('----------------------------------','\\n','             Predicted Class', file=text_file)\n",
    "            print(table_t, file=text_file)\n",
    "            print(\"\",file=text_file)\n",
    "            print(\"Model Summary (Test)\", file=text_file)\n",
    "            print('------------------------------', file=text_file)\n",
    "            print(\"Overall accuracy = \", accuracy_t.round(3), sep='', file=text_file)\n",
    "            print('', file=text_file)\n",
    "        print(\"Output file has been successfully saved in \",os.getcwd(),\"/\",outputname,sep=\"\") \n",
    "\n",
    "    \n",
    "    ################################\n",
    "    ### (iv) Logistic Regression ###\n",
    "    ################################\n",
    "    \n",
    "    if choice == 4 :\n",
    "        # import packages\n",
    "        import math\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from pandas import DataFrame as df\n",
    "        from scipy.optimize import minimize\n",
    "\n",
    "        # Basic matrix for Logistic\n",
    "        n = train.shape[0]\n",
    "        n_t = test.shape[0]\n",
    "        ex = train.drop(num, axis=1)\n",
    "        x = pd.concat([pd.DataFrame(np.repeat(1,n)),ex], axis=1)\n",
    "        ex_t = test.drop(num, axis=1)\n",
    "        x_t = pd.concat([pd.DataFrame(np.repeat(1,n_t)),ex_t], axis=1)\n",
    "        y = train[num]\n",
    "        y_t = test[num]\n",
    "        p = train.shape[1]\n",
    "\n",
    "        def loglike(B):\n",
    "            return - np.dot((y-1).T,x).dot(B) + sum(np.log(1+np.exp(np.dot(x,B))))\n",
    "        loglik = minimize(loglike, np.repeat(0,p))\n",
    "        b = loglik.x\n",
    "        print('The result that maximizes Log-Likelihood of Logistic Regression(MLE method).')\n",
    "        print(df(b))\n",
    "\n",
    "        cutoff = input('Enter the cutoff value from 0 to 1. : ')\n",
    "        cutoff = float(cutoff)\n",
    "        if not (0<=cutoff<=1) : \n",
    "            cutoff=0.5\n",
    "            print('The cutoff value must be in 0 to 1. So set 0.5 as the cutoff value.')\n",
    "\n",
    "        # Training data\n",
    "        prob = np.round(np.exp(np.dot(x,b))/(1+np.exp(np.dot(x,b))), 3)\n",
    "        c = np.repeat(0,n)\n",
    "        c[prob >= cutoff]=2\n",
    "        c[prob <= cutoff]=1\n",
    "\n",
    "        # Test data\n",
    "        prob_t = np.round(np.exp(np.dot(x_t,b))/(1+np.exp(np.dot(x_t,b))), 3)\n",
    "        c_t = np.repeat(0,n_t)\n",
    "        c_t[prob_t >= cutoff]=2\n",
    "        c_t[prob_t <= cutoff]=1\n",
    "\n",
    "        # Output setting\n",
    "        out_num = int(input('Please enter the maximum output row you want to have in the output file. :' ))\n",
    "\n",
    "        # Crosstable\n",
    "        con = df({'Actual Class':y, 'Predicted Class':c})\n",
    "        table = pd.crosstab(con['Actual Class'],con['Predicted Class'], colnames=[''])\n",
    "        accuracy = np.trace(table)/n\n",
    "        sensi = table.loc[2,2]/sum(table.loc[2,])\n",
    "        speci = table.loc[1,1]/sum(table.loc[1,])\n",
    "\n",
    "        con_t = df({'Actual Class':y_t, 'Predicted Class':c_t})\n",
    "        table_t = pd.crosstab(con_t['Actual Class'],con_t['Predicted Class'], colnames=[''])\n",
    "        accuracy_t = np.trace(table_t)/n_t\n",
    "        sensi_t = table_t.loc[2,2]/sum(table_t.loc[2,])\n",
    "        speci_t = table_t.loc[1,1]/sum(table_t.loc[1,])\n",
    "\n",
    "        # output file\n",
    "        outputname = input(\"Write the output file name you want to save (without extension name) : \")\n",
    "        outputname = outputname+'.txt'\n",
    "\n",
    "        with open(outputname,\"w\") as text_file:\n",
    "\n",
    "            print('ID, Actual class, Resub pred, Pred Prob', file=text_file)\n",
    "            print('-----------------------------', file=text_file)\n",
    "            for i in range(0, out_num):\n",
    "                 print(i+1, y[i], c[i], prob[i], sep=', ', file=text_file)\n",
    "            print('(continue)',file=text_file)        \n",
    "            print('',file=text_file)\n",
    "\n",
    "            print('Confusion Matrix (Resubstitution)', file=text_file)\n",
    "            print('----------------------------------','\\n','             Predicted Class', file=text_file)\n",
    "            print(table, file=text_file)\n",
    "            print(\"\",file=text_file)\n",
    "\n",
    "            print(\"Model Summary (Resubstitution)\", file=text_file)\n",
    "            print('------------------------------', file=text_file)\n",
    "            print(\"Overall accuracy = \", accuracy.round(3), sep='', file=text_file)\n",
    "            print(\"Sensitivity = \", sensi.round(3), sep='', file=text_file)\n",
    "            print(\"Specificity = \", speci.round(3), sep='', file=text_file)\n",
    "            print('', file=text_file)\n",
    "\n",
    "            print('ID, Actual class, Test pred, Pred Prob', file=text_file)\n",
    "            print('-----------------------------', file=text_file)\n",
    "            for i in range(0, out_num):\n",
    "                print(i+1, y_t[i], c_t[i], prob[i], sep=', ', file=text_file)\n",
    "            print('(continue)',file=text_file)        \n",
    "            print('',file=text_file)\n",
    "\n",
    "            print('Confusion Matrix (Test)', file=text_file)\n",
    "            print('----------------------------------','\\n','             Predicted Class', file=text_file)\n",
    "            print(table_t, file=text_file)\n",
    "            print(\"\",file=text_file)\n",
    "\n",
    "            print(\"Model Summary (Test)\", file=text_file)\n",
    "            print('------------------------------', file=text_file)\n",
    "            print(\"Overall accuracy = \", accuracy_t.round(3), sep='', file=text_file)\n",
    "            print(\"Sensitivity = \", sensi_t.round(3), sep='', file=text_file)\n",
    "            print(\"Specificity = \", speci_t.round(3), sep='', file=text_file)\n",
    "            print('', file=text_file)\n",
    "        print(\"Output file has been successfully saved in \",os.getcwd(),\"/\",outputname,sep=\"\") \n",
    "        \n",
    "\n",
    "    ###########################\n",
    "    ##### (v) Naive Bayes #####\n",
    "    ###########################\n",
    "\n",
    "    if choice == 5 :\n",
    "\n",
    "        import pandas as pd\n",
    "        from pandas import DataFrame as df\n",
    "        import numpy as np\n",
    "        from scipy.stats import norm\n",
    "\n",
    "        # Basic matrixs\n",
    "        n = train.shape[0]\n",
    "        n_t = test.shape[0]\n",
    "        x = train.drop(num, axis=1)\n",
    "        x_t = test.drop(num, axis=1)\n",
    "        y = train[num]\n",
    "        y_t = test[num]\n",
    "        p = train.shape[1]\n",
    "\n",
    "        # set variable attributes\n",
    "        print(' It has',k,'variables.','\\n', \n",
    "              'Input variable number which has numerical attribute.','\\n',\n",
    "              'ex) 1, 3, 5','\\n')\n",
    "        numer = input('Numerical attributes : ').split(',')\n",
    "        numer = (np.array(numer).astype('int')-1).tolist()\n",
    "\n",
    "        # probabiliy of training set\n",
    "        t1 = train[train.loc[:,num]==1]\n",
    "        t2 = train[train.loc[:,num]==2]\n",
    "        prob_1 = np.ones((n,p))\n",
    "        prob_2 = np.ones((n,p))\n",
    "\n",
    "        nnn=list(range(0,p))\n",
    "        nnn.remove(num)\n",
    "\n",
    "        for i in range(0,n) :\n",
    "            for j in nnn :\n",
    "                if(train.loc[i,j] != '?') : \n",
    "                    if(j in numer) :\n",
    "                        prob_1[i,j] = norm.pdf(train.loc[i,j], loc=np.mean(t1.loc[:,j]), scale=np.std(t1.loc[:,j]) )\n",
    "                        prob_2[i,j] = norm.pdf(train.loc[i,j], loc=np.mean(t2.loc[:,j]), scale=np.std(t2.loc[:,j]) )\n",
    "                    else :\n",
    "                        t = pd.crosstab(y, x.loc[:,j]).apply(lambda r: r/r.sum(), axis=1)\n",
    "                        prob_1[i,j] = t.loc[1,train.loc[i,j]]\n",
    "                        prob_2[i,j] = t.loc[2,train.loc[i,j]]\n",
    "\n",
    "        prob_temp = np.c_[np.prod(prob_1, axis=1), np.prod(prob_2, axis=1) ]\n",
    "        prob = np.zeros((n,2))\n",
    "        prob[:,0] = np.round(prob_temp[:,0]/prob_temp.sum(axis=1),3)\n",
    "        prob[:,1] = np.round(prob_temp[:,1]/prob_temp.sum(axis=1),3)\n",
    "        c = df(prob, columns=[1,2]).idxmax(axis=1)\n",
    "\n",
    "        # probability of test set\n",
    "        prob_1_t = np.ones((n_t,p))\n",
    "        prob_2_t = np.ones((n_t,p))\n",
    "\n",
    "        for i in range(0,n_t) :\n",
    "            for j in nnn :\n",
    "                if(test.loc[i,j] != '?') : \n",
    "                    if(j in numer) :\n",
    "                        prob_1_t[i,j] = norm.pdf(test.loc[i,j], loc=np.mean(t1.loc[:,j]), scale=np.std(t1.loc[:,j]) )\n",
    "                        prob_2_t[i,j] = norm.pdf(test.loc[i,j], loc=np.mean(t2.loc[:,j]), scale=np.std(t2.loc[:,j]) )\n",
    "                    else :\n",
    "                        t = pd.crosstab(y, x.loc[:,j]).apply(lambda r: r/r.sum(), axis=1)\n",
    "                        prob_1_t[i,j] = t.loc[1,test.loc[i,j]]\n",
    "                        prob_2_t[i,j] = t.loc[2,test.loc[i,j]]\n",
    "\n",
    "        prob_temp_t = np.c_[np.prod(prob_1_t, axis=1), np.prod(prob_2_t, axis=1) ]\n",
    "        prob_t = np.zeros((n_t,2))\n",
    "        prob_t[:,0] = np.round(prob_temp_t[:,0]/prob_temp_t.sum(axis=1),3)\n",
    "        prob_t[:,1] = np.round(prob_temp_t[:,1]/prob_temp_t.sum(axis=1),3)\n",
    "        prob_t\n",
    "\n",
    "        c_t = df(prob_t, columns=[1,2]).idxmax(axis=1)\n",
    "\n",
    "        # Output setting\n",
    "        out_num = int(input('Please enter the maximum output row you want to have in the output file. :' ))\n",
    "\n",
    "        # Crosstable\n",
    "        con = df({'Actual Class':y, 'Predicted Class':c})\n",
    "        table = pd.crosstab(con['Actual Class'],con['Predicted Class'], colnames=[''])\n",
    "        accuracy = np.trace(table)/n\n",
    "        sensi = table.loc[2,2]/sum(table.loc[2,])\n",
    "        speci = table.loc[1,1]/sum(table.loc[1,])\n",
    "\n",
    "        con_t = df({'Actual Class':y_t, 'Predicted Class':c_t})\n",
    "        table_t = pd.crosstab(con_t['Actual Class'],con_t['Predicted Class'], colnames=[''])\n",
    "        accuracy_t = np.trace(table_t)/n_t\n",
    "        sensi_t = table_t.loc[2,2]/sum(table_t.loc[2,])\n",
    "        speci_t = table_t.loc[1,1]/sum(table_t.loc[1,])\n",
    "\n",
    "        # output file\n",
    "        outputname = input(\"Write the output file name you want to save (without extension name) : \")\n",
    "        outputname = outputname+'.txt'\n",
    "        import os as os\n",
    "        with open(outputname,\"w\") as text_file:\n",
    "\n",
    "            print('ID, Actual class, Resub pred, Pred Prob', file=text_file)\n",
    "            print('-----------------------------', file=text_file)\n",
    "            for i in range(0, out_num):\n",
    "                 print(i+1, y[i], c[i], prob[i][c[i]-1], sep=', ', file=text_file)\n",
    "            print('(continue)',file=text_file)        \n",
    "            print('',file=text_file)\n",
    "\n",
    "            print('Confusion Matrix (Resubstitution)', file=text_file)\n",
    "            print('----------------------------------','\\n','             Predicted Class', file=text_file)\n",
    "            print(table, file=text_file)\n",
    "            print(\"\",file=text_file)\n",
    "\n",
    "            print(\"Model Summary (Resubstitution)\", file=text_file)\n",
    "            print('------------------------------', file=text_file)\n",
    "            print(\"Overall accuracy = \", accuracy.round(3), sep='', file=text_file)\n",
    "            print(\"Sensitivity = \", sensi.round(3), sep='', file=text_file)\n",
    "            print(\"Specificity = \", speci.round(3), sep='', file=text_file)\n",
    "            print('', file=text_file)\n",
    "\n",
    "            print('ID, Actual class, Test pred, Pred Prob', file=text_file)\n",
    "            print('-----------------------------', file=text_file)\n",
    "            for i in range(0, out_num):\n",
    "                print(i+1, y_t[i], c_t[i], prob[i][c[i]-1], sep=', ', file=text_file)\n",
    "            print('(continue)',file=text_file)        \n",
    "            print('',file=text_file)\n",
    "\n",
    "            print('Confusion Matrix (Test)', file=text_file)\n",
    "            print('----------------------------------','\\n','             Predicted Class', file=text_file)\n",
    "            print(table_t, file=text_file)\n",
    "            print(\"\",file=text_file)\n",
    "\n",
    "            print(\"Model Summary (Test)\", file=text_file)\n",
    "            print('------------------------------', file=text_file)\n",
    "            print(\"Overall accuracy = \", accuracy_t.round(3), sep='', file=text_file)\n",
    "            print(\"Sensitivity = \", sensi_t.round(3), sep='', file=text_file)\n",
    "            print(\"Specificity = \", speci_t.round(3), sep='', file=text_file)\n",
    "            print('', file=text_file)\n",
    "\n",
    "        print(\"Output file has been successfully saved in \",os.getcwd(),\"/\",outputname,sep=\"\")\n",
    "        \n",
    "    #####################################\n",
    "    ##### (v) 1-level decision tree #####\n",
    "    #####################################\n",
    "    \n",
    "    if choice == 6 :\n",
    "        \n",
    "        # Basic matrixs\n",
    "        n = train.shape[0]\n",
    "        n_t = test.shape[0]\n",
    "        x = train.drop(num, axis=1)\n",
    "        x_t = test.drop(num, axis=1)\n",
    "        y = train[num]\n",
    "        y_t = test[num]\n",
    "        p = train.shape[1]\n",
    "        \n",
    "        nnn=list(range(0,p))\n",
    "        nnn.remove(num)\n",
    "        classes = np.unique(y)\n",
    "        classes.sort\n",
    "        \n",
    "        # Greedy search for continuous variable\n",
    "        GoS = []\n",
    "        split = []\n",
    "        for j in nnn :\n",
    "            value = np.unique(x[j])\n",
    "            value.sort()\n",
    "            t = len(value)\n",
    "            goodness = []\n",
    "            s = []\n",
    "            print('Start Greedy Search for', nnn[j]+1, 'th column.')\n",
    "            print('Repeat ',t-1,'times.','\\n')\n",
    "\n",
    "            for i in range(0,(t-1)) :\n",
    "                s.append(np.mean(value[[i, (i+1)]]))\n",
    "                #for i in range(0, (t-1)) :\n",
    "                print('Split at ', s[i])\n",
    "                t1 = train.loc[ train[j] <= s[i], num ]\n",
    "                t2 = train.loc[ train[j] > s[i], num ]\n",
    "                n = len(y)\n",
    "                n1 = len(t1)\n",
    "                n2 = len(t2)\n",
    "                # Gini impurity\n",
    "                imp_t1 = 1- (sum(t1==classes[0])/n1)**2 - (sum(t1==classes[1])/n1)**2\n",
    "                imp_t2 = 1- (sum(t2==classes[0])/n2)**2 - (sum(t2==classes[1])/n2)**2\n",
    "                # Goodness of split\n",
    "                imp_t = 1- (sum(y==classes[0])/n)**2 - (sum(y==classes[1])/n)**2\n",
    "                goodness.append(imp_t - n1/n*imp_t1 - n2/n*imp_t2)\n",
    "                print('Goodness of split is ', np.round(goodness[i],4))\n",
    "\n",
    "            GoS.append(max(goodness))\n",
    "            split.append(s[goodness.index(max(goodness))])\n",
    "            print('\\n')\n",
    "\n",
    "        # result\n",
    "        result = np.c_[split, GoS]\n",
    "        result = pd.DataFrame(result, columns=['split', 'Goodness of Split'], index=nnn)\n",
    "        print(result)\n",
    "        j = result.idxmax()['Goodness of Split']\n",
    "        var_1 = result.index[j]\n",
    "        split_1 = result['split'][j]\n",
    "        print('Node 1 is ', var_1, 'and split at ', split_1)\n",
    "        \n",
    "        # training set\n",
    "        t1 = train.loc[ train[j] <= split_1, num ]\n",
    "        t2 = train.loc[ train[j] > split_1, num ]\n",
    "        c = np.repeat(0,n)\n",
    "        c[t1.index] = classes[0]\n",
    "        c[t2.index] = classes[1]\n",
    "\n",
    "        # test set\n",
    "        t1_t = test.loc[ test[j] <= split_1, num ]\n",
    "        t2_t = test.loc[ test[j] > split_1, num ]\n",
    "        c_t = np.repeat(0,n_t)\n",
    "        c_t[t1_t.index] = classes[0]\n",
    "        c_t[t2_t.index] = classes[1]\n",
    "\n",
    "        # Crosstable\n",
    "        con = df({'Actual Class':y, 'Predicted Class':c})\n",
    "        table = pd.crosstab(con['Actual Class'],con['Predicted Class'], colnames=[''])\n",
    "        accuracy = np.trace(table)/n\n",
    "        sensi = table.iloc[1,1]/sum(table.iloc[1])\n",
    "        speci = table.iloc[0,0]/sum(table.iloc[0])\n",
    "\n",
    "        con_t = df({'Actual Class':y_t, 'Predicted Class':c_t})\n",
    "        table_t = pd.crosstab(con_t['Actual Class'],con_t['Predicted Class'], colnames=[''])\n",
    "        accuracy_t = np.trace(table_t)/n_t\n",
    "        sensi_t = table_t.iloc[1,1]/sum(table_t.iloc[1])\n",
    "        speci_t = table_t.iloc[0,0]/sum(table_t.iloc[0])\n",
    "        \n",
    "        # output file\n",
    "        out_num = int(input('Please enter the maximum output row you want to have in the output file. :' ))\n",
    "        outputname = input(\"Write the output file name you want to save (without extension name) : \")\n",
    "        outputname = outputname+'.txt'\n",
    "        with open(outputname,\"w\") as text_file:\n",
    "            print('Tree Structure', file=text_file)\n",
    "            print('\\t', 'Node 1: ', var_1, ' <= ', split_1, ' (', y.tolist().count(classes[0]),',', y.tolist().count(classes[1]), ')', file=text_file)\n",
    "            print('\\t', 'Node 2: ', classes[0], ' (', t1.tolist().count(classes[0]),',', t1.tolist().count(classes[1]), ')', file=text_file)\n",
    "            print('\\t', 'Node 3: ', classes[0], ' (', t2.tolist().count(classes[0]),',', t2.tolist().count(classes[1]), ')', file=text_file)\n",
    "\n",
    "            print('ID, Actual class, Resub pred', file=text_file)\n",
    "            print('-----------------------------', file=text_file)\n",
    "            for i in range(0, out_num):\n",
    "                 print(i+1, y[i], c[i], sep=', ', file=text_file)\n",
    "            print('(continue)',file=text_file)        \n",
    "            print('',file=text_file)\n",
    "\n",
    "            print('Confusion Matrix (Resubstitution)', file=text_file)\n",
    "            print('----------------------------------','\\n','             Predicted Class', file=text_file)\n",
    "            print(table, file=text_file)\n",
    "            print(\"\",file=text_file)\n",
    "\n",
    "            print(\"Model Summary (Resubstitution)\", file=text_file)\n",
    "            print('------------------------------', file=text_file)\n",
    "            print(\"Overall accuracy = \", accuracy.round(3), sep='', file=text_file)\n",
    "            print(\"Sensitivity = \", sensi.round(3), sep='', file=text_file)\n",
    "            print(\"Specificity = \", speci.round(3), sep='', file=text_file)\n",
    "            print('', file=text_file)\n",
    "\n",
    "            print('ID, Actual class, Test pred', file=text_file)\n",
    "            print('-----------------------------', file=text_file)\n",
    "            for i in range(0, out_num):\n",
    "                print(i+1, y_t[i], c_t[i], sep=', ', file=text_file)\n",
    "            print('(continue)',file=text_file)        \n",
    "            print('',file=text_file)\n",
    "\n",
    "            print('Confusion Matrix (Test)', file=text_file)\n",
    "            print('----------------------------------','\\n','             Predicted Class', file=text_file)\n",
    "            print(table_t, file=text_file)\n",
    "            print(\"\",file=text_file)\n",
    "\n",
    "            print(\"Model Summary (Test)\", file=text_file)\n",
    "            print('------------------------------', file=text_file)\n",
    "            print(\"Overall accuracy = \", accuracy_t.round(3), sep='', file=text_file)\n",
    "            print(\"Sensitivity = \", sensi_t.round(3), sep='', file=text_file)\n",
    "            print(\"Specificity = \", speci_t.round(3), sep='', file=text_file)\n",
    "            print('', file=text_file)\n",
    "\n",
    "        print(\"Output file has been successfully saved in \",os.getcwd(),\"/\",outputname,sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HW7() :\n",
    "    print('Checking the working environment.')\n",
    "    mylib()\n",
    "    ans = int(input('Enter 1 to use Regression, Enter 2 to use Classification : '))\n",
    "    if ans == 1 : \n",
    "        regression_analysis()\n",
    "    elif ans == 2 :\n",
    "        classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the working environment.\n",
      "Write the location of the data file. : C:/Users/User/Desktop/18-2/DM/data\n",
      "Working Directory is now  C:\\Users\\User\\Desktop\\18-2\\DM\\data\n",
      "Enter 1 to use Regression, Enter 2 to use Classification : 2\n",
      "Importing TRAINING dataset\n",
      "Enter the data file name (with extension name) : harris.dat\n",
      "Select the data coding format(1='a b c' or 2='a,b,c'): 1\n",
      "Importing TEST dataset\n",
      "Enter the data file name (with extension name) : harris.dat\n",
      "Select the data coding format(1='a b c' or 2='a,b,c'): 1\n",
      "Enter which column the response variable is recorded: 5\n",
      "Enter 1 for LDA, 2 for QDA, 3 for RDA , 4 for Logistic Regression, 5 for Naive Bayes or 6 for 1-level decision tree. : 6\n",
      "Start Greedy Search for 1 th column.\n",
      "Repeat  25 times. \n",
      "\n",
      "Split at  3960.0\n",
      "Goodness of split is  0.0026\n",
      "Split at  4155.0\n",
      "Goodness of split is  0.0052\n",
      "Split at  4335.0\n",
      "Goodness of split is  0.0079\n",
      "Split at  4410.0\n",
      "Goodness of split is  0.0223\n",
      "Split at  4470.0\n",
      "Goodness of split is  0.0254\n",
      "Split at  4560.0\n",
      "Goodness of split is  0.0318\n",
      "Split at  4710.0\n",
      "Goodness of split is  0.0232\n",
      "Split at  4890.0\n",
      "Goodness of split is  0.0594\n",
      "Split at  5010.0\n",
      "Goodness of split is  0.0636\n",
      "Split at  5070.0\n",
      "Goodness of split is  0.0513\n",
      "Split at  5130.0\n",
      "Goodness of split is  0.0546\n",
      "Split at  5190.0\n",
      "Goodness of split is  0.0591\n",
      "Split at  5250.0\n",
      "Goodness of split is  0.0577\n",
      "Split at  5340.0\n",
      "Goodness of split is  0.0725\n",
      "Split at  5460.0\n",
      "Goodness of split is  0.0901\n",
      "Split at  5550.0\n",
      "Goodness of split is  0.1058\n",
      "Split at  5610.0\n",
      "Goodness of split is  0.1145\n",
      "Split at  5670.0\n",
      "Goodness of split is  0.1237\n",
      "Split at  5850.0\n",
      "Goodness of split is  0.1668\n",
      "Split at  6060.0\n",
      "Goodness of split is  0.0394\n",
      "Split at  6210.0\n",
      "Goodness of split is  0.0501\n",
      "Split at  6450.0\n",
      "Goodness of split is  0.07\n",
      "Split at  6720.0\n",
      "Goodness of split is  0.0387\n",
      "Split at  6870.0\n",
      "Goodness of split is  0.0287\n",
      "Split at  7500.0\n",
      "Goodness of split is  0.0094\n",
      "\n",
      "\n",
      "Start Greedy Search for 2 th column.\n",
      "Repeat  4 times. \n",
      "\n",
      "Split at  9.0\n",
      "Goodness of split is  0.0201\n",
      "Split at  11.0\n",
      "Goodness of split is  0.0232\n",
      "Split at  13.5\n",
      "Goodness of split is  0.0417\n",
      "Split at  15.5\n",
      "Goodness of split is  0.0022\n",
      "\n",
      "\n",
      "Start Greedy Search for 3 th column.\n",
      "Repeat  78 times. \n",
      "\n",
      "Split at  2.25\n",
      "Goodness of split is  0.0079\n",
      "Split at  4.75\n",
      "Goodness of split is  0.0106\n",
      "Split at  5.5\n",
      "Goodness of split is  0.0135\n",
      "Split at  6.1\n",
      "Goodness of split is  0.0163\n",
      "Split at  6.6\n",
      "Goodness of split is  0.0193\n",
      "Split at  7.25\n",
      "Goodness of split is  0.009\n",
      "Split at  7.75\n",
      "Goodness of split is  0.0116\n",
      "Split at  9.5\n",
      "Goodness of split is  0.0144\n",
      "Split at  11.25\n",
      "Goodness of split is  0.0201\n",
      "Split at  12.75\n",
      "Goodness of split is  0.0118\n",
      "Split at  15.75\n",
      "Goodness of split is  0.006\n",
      "Split at  17.75\n",
      "Goodness of split is  0.0023\n",
      "Split at  21.0\n",
      "Goodness of split is  0.0037\n",
      "Split at  24.5\n",
      "Goodness of split is  0.0021\n",
      "Split at  25.5\n",
      "Goodness of split is  0.0004\n",
      "Split at  27.5\n",
      "Goodness of split is  0.0011\n",
      "Split at  30.5\n",
      "Goodness of split is  0.0001\n",
      "Split at  33.75\n",
      "Goodness of split is  0.0002\n",
      "Split at  35.75\n",
      "Goodness of split is  0.0015\n",
      "Split at  37.0\n",
      "Goodness of split is  0.0013\n",
      "Split at  39.75\n",
      "Goodness of split is  0.002\n",
      "Split at  42.75\n",
      "Goodness of split is  0.0044\n",
      "Split at  44.75\n",
      "Goodness of split is  0.003\n",
      "Split at  47.25\n",
      "Goodness of split is  0.0057\n",
      "Split at  50.0\n",
      "Goodness of split is  0.0071\n",
      "Split at  51.5\n",
      "Goodness of split is  0.0038\n",
      "Split at  53.25\n",
      "Goodness of split is  0.0016\n",
      "Split at  54.75\n",
      "Goodness of split is  0.0035\n",
      "Split at  55.5\n",
      "Goodness of split is  0.0024\n",
      "Split at  57.5\n",
      "Goodness of split is  0.0078\n",
      "Split at  60.0\n",
      "Goodness of split is  0.0061\n",
      "Split at  62.0\n",
      "Goodness of split is  0.0045\n",
      "Split at  63.5\n",
      "Goodness of split is  0.0032\n",
      "Split at  67.0\n",
      "Goodness of split is  0.0093\n",
      "Split at  71.0\n",
      "Goodness of split is  0.0074\n",
      "Split at  73.5\n",
      "Goodness of split is  0.0112\n",
      "Split at  76.75\n",
      "Goodness of split is  0.0091\n",
      "Split at  80.25\n",
      "Goodness of split is  0.0073\n",
      "Split at  83.0\n",
      "Goodness of split is  0.0056\n",
      "Split at  85.25\n",
      "Goodness of split is  0.0091\n",
      "Split at  88.25\n",
      "Goodness of split is  0.0072\n",
      "Split at  93.0\n",
      "Goodness of split is  0.0041\n",
      "Split at  96.5\n",
      "Goodness of split is  0.0029\n",
      "Split at  99.5\n",
      "Goodness of split is  0.0019\n",
      "Split at  104.5\n",
      "Goodness of split is  0.0011\n",
      "Split at  107.5\n",
      "Goodness of split is  0.0005\n",
      "Split at  110.5\n",
      "Goodness of split is  0.0019\n",
      "Split at  114.0\n",
      "Goodness of split is  0.0041\n",
      "Split at  115.75\n",
      "Goodness of split is  0.0029\n",
      "Split at  118.75\n",
      "Goodness of split is  0.0019\n",
      "Split at  121.5\n",
      "Goodness of split is  0.001\n",
      "Split at  122.5\n",
      "Goodness of split is  0.0004\n",
      "Split at  125.0\n",
      "Goodness of split is  0.0001\n",
      "Split at  129.5\n",
      "Goodness of split is  0.0\n",
      "Split at  132.25\n",
      "Goodness of split is  0.0004\n",
      "Split at  138.25\n",
      "Goodness of split is  0.0001\n",
      "Split at  153.5\n",
      "Goodness of split is  0.0\n",
      "Split at  164.0\n",
      "Goodness of split is  0.0002\n",
      "Split at  167.0\n",
      "Goodness of split is  0.0008\n",
      "Split at  171.0\n",
      "Goodness of split is  0.0017\n",
      "Split at  174.0\n",
      "Goodness of split is  0.003\n",
      "Split at  177.5\n",
      "Goodness of split is  0.001\n",
      "Split at  185.0\n",
      "Goodness of split is  0.0\n",
      "Split at  193.0\n",
      "Goodness of split is  0.0004\n",
      "Split at  202.25\n",
      "Goodness of split is  0.0012\n",
      "Split at  211.25\n",
      "Goodness of split is  0.0025\n",
      "Split at  214.75\n",
      "Goodness of split is  0.0045\n",
      "Split at  221.75\n",
      "Goodness of split is  0.0016\n",
      "Split at  229.5\n",
      "Goodness of split is  0.0059\n",
      "Split at  236.0\n",
      "Goodness of split is  0.0096\n",
      "Split at  242.5\n",
      "Goodness of split is  0.0149\n",
      "Split at  248.0\n",
      "Goodness of split is  0.0223\n",
      "Split at  262.0\n",
      "Goodness of split is  0.0144\n",
      "Split at  293.5\n",
      "Goodness of split is  0.0074\n",
      "Split at  316.5\n",
      "Goodness of split is  0.0022\n",
      "Split at  319.0\n",
      "Goodness of split is  0.0069\n",
      "Split at  339.5\n",
      "Goodness of split is  0.0011\n",
      "Split at  370.0\n",
      "Goodness of split is  0.0026\n",
      "\n",
      "\n",
      "Start Greedy Search for 4 th column.\n",
      "Repeat  30 times. \n",
      "\n",
      "Split at  1.5\n",
      "Goodness of split is  0.0135\n",
      "Split at  2.5\n",
      "Goodness of split is  0.0017\n",
      "Split at  3.5\n",
      "Goodness of split is  0.0005\n",
      "Split at  4.5\n",
      "Goodness of split is  0.0001\n",
      "Split at  5.5\n",
      "Goodness of split is  0.0012\n",
      "Split at  6.5\n",
      "Goodness of split is  0.0\n",
      "Split at  7.5\n",
      "Goodness of split is  0.0001\n",
      "Split at  8.5\n",
      "Goodness of split is  0.0015\n",
      "Split at  9.5\n",
      "Goodness of split is  0.0007\n",
      "Split at  10.5\n",
      "Goodness of split is  0.0013\n",
      "Split at  11.5\n",
      "Goodness of split is  0.0027\n",
      "Split at  12.5\n",
      "Goodness of split is  0.0008\n",
      "Split at  13.5\n",
      "Goodness of split is  0.0007\n",
      "Split at  14.5\n",
      "Goodness of split is  0.0013\n",
      "Split at  15.5\n",
      "Goodness of split is  0.0006\n",
      "Split at  16.5\n",
      "Goodness of split is  0.0073\n",
      "Split at  18.0\n",
      "Goodness of split is  0.0091\n",
      "Split at  19.5\n",
      "Goodness of split is  0.0112\n",
      "Split at  20.5\n",
      "Goodness of split is  0.0091\n",
      "Split at  21.5\n",
      "Goodness of split is  0.014\n",
      "Split at  22.5\n",
      "Goodness of split is  0.0145\n",
      "Split at  23.5\n",
      "Goodness of split is  0.01\n",
      "Split at  24.5\n",
      "Goodness of split is  0.0128\n",
      "Split at  25.5\n",
      "Goodness of split is  0.0085\n",
      "Split at  26.5\n",
      "Goodness of split is  0.0066\n",
      "Split at  28.0\n",
      "Goodness of split is  0.0034\n",
      "Split at  29.5\n",
      "Goodness of split is  0.0004\n",
      "Split at  31.0\n",
      "Goodness of split is  0.0005\n",
      "Split at  32.5\n",
      "Goodness of split is  0.0001\n",
      "Split at  33.5\n",
      "Goodness of split is  0.0052\n",
      "\n",
      "\n",
      "    split  Goodness of Split\n",
      "0  5850.0           0.166812\n",
      "1    13.5           0.041739\n",
      "2   248.0           0.022310\n",
      "3    22.5           0.014515\n",
      "Node 1 is  0 and split at  5850.0\n",
      "Please enter the maximum output row you want to have in the output file. :5\n",
      "Write the output file name you want to save (without extension name) : HW7KimDA_tree_py_output\n",
      "Output file has been successfully saved in C:\\Users\\User\\Desktop\\18-2\\DM\\data/HW7KimDA_tree_py_output.txt\n"
     ]
    }
   ],
   "source": [
    "HW7() #C:/Users/User/Desktop/18-2/DM/data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
