#################### DM - HW4 ####################
############### 2018314030 김단아 ################

################
#### R Code ####
################



rm(list=ls())
mylib = "C:\\Users\\User\\Desktop\\18-2\\DM\\data"  # veh.dat이 존재하는 위치로 지정해주어야한다.
setwd(mylib)
getwd()

# For 3D graphic output 
#install.packages("rgl")
library(rgl)



### importing dataset function ###

read = function(){
  data = readline("Enter the data file name (with extension name) : " )
  cat("Select the data coding format(1 = 'a b c' or 2 = 'a,b,c'): ")
  fm = scan(n=1, quiet=TRUE)
  if(fm == 1){form=""} else {form=","}
  read.table(data, sep=form)
}


### regressoin function ###

regression <- function() {
  
  # import data file
  data = read()
  
  # enter the Column number
  cat("Enter which column the response variable is recorded: ")
  num = scan(n=1, quiet=TRUE)
  
  # design matrix
  n = dim(data)[1]
  p = dim(data)[2]-1
  one = matrix(1, nrow=n, ncol=1)
  I = diag(n)
  
  y = as.matrix(data[,num])
  x = as.matrix(cbind(one,data[,-num]))
  H = x%*%solve(t(x)%*%x)%*%t(x)
  H0 = one%*%solve(t(one)%*%one)%*%t(one)
  
  # multiple regression result
  b = round(solve(t(x)%*%x)%*%t(x)%*%y, 3)
  yhat = x%*%b
  SST = t(y)%*%(I-H0)%*%y
  SSE = t(y)%*%(I-H)%*%y
  Rsquare = round(1 - SSE/SST, 4)
  MSE = round(SSE/(n-p), 4)
  
  # output - coefficient
  name = paste("Beta",c(0:p),":" ,sep="")
  name[1] = "Constant:"
  row.names(b) = name
  
  # output - ID, Actual values, Fitted values
  y.values = cbind(c(1:n), y, round(yhat,1))
  
  # output- Model Summary
  model.smy = rbind(Rsquare, MSE)
  row.names(model.smy) = c("R-square = ","MSE = ")
  
  # make output file
  outputname = readline("Write the output file name you want to save (without extension name) : ")
  outputname = paste(outputname,".txt",sep="")
  
  cat("Coefficients","\n","-------------","\n",file = outputname,sep="")
  write.table(b, outputname, sep= "   ", row.names=TRUE, col.names=FALSE, append=TRUE, quote=FALSE)
  
  cat("\n","ID, Actual values, Fitted values","\n","--------------------------------","\n",file = outputname,sep="", append=TRUE)
  write.table(y.values, outputname, sep= ", ", row.names=FALSE, col.names=FALSE, append=TRUE, quote=FALSE)
  
  cat("\n","Model Summary","\n","-------------","\n",file = outputname,sep="", append=TRUE)
  write.table(model.smy, outputname, sep= "", row.names=TRUE, col.names=FALSE, append=TRUE, quote=FALSE)
  
  cat("Output file has been saved in ",getwd(),"/",outputname,sep="")
}


### classification function ###

classification <- function() {
  
  # import training & test data file
  cat('Import the dataset of TRAINING','\n')
  train = read()
  cat('Import the dataset of TEST','\n')
  test = read()
  
  # enter the Column number
  cat("Enter which column the response variable is recorded: ")
  num = scan(n=1, quiet=TRUE)
  
  # choose (i)LDA or (ii)QDA or (iii)RDA
  cat("Enter 1 to implement LDA, 2 to implement QDA or 3 to implement RDA")
  choice = scan(n=1, quiet=TRUE)
  
  # nclass of response variable
  k = length(unique(train[,num]))      # Assume that values of the class variable are integers starting with 1

  # set prior
  cat('It has',k,'Classes.','\n',
      'Input each priors with ascending order of Class index.','\n',
      'ex) Priors of 3 class size = 1/3, 1/3, 1/3','\n')
  prior = strsplit(readline('Priors :'),split=",")[[1]]
  
  # Error type 1
  if (length(prior)!= k) {cat('Your Prior input does not correspond with class size.','\n') 
    ; prior = paste(rep(1, k),'/',k,sep="")
    ; cat('So equal prior is given such as', prior)}
  
  prior = as.vector(sapply(prior, function(x){eval(parse(text=prior))}))
  # Error type 2
  if (length(sum(prior))!= 1) {cat('Sum of your prior input is not equal to 1','\n')
    ; prior = paste(rep(1, k),'/',k,sep="")
    ; cat('So equal prior is given such as', prior)}
  
  # Basic vectors
  n = nrow(train)
  n.t = nrow(test)
  x = t(train[-num])
  x.t = t((test[,-num]))
  y = train[,num]
  y.t = test[,num]
  p = ncol(train)-1
  
  means = t(as.matrix(aggregate(train[-num], train[num], mean)[,-1]))
  sk = lapply(lapply(split(train,train[,num]), function(x){x[,-num]}), cov)
  sp_nonsum = lapply( sk, function(x){ (nrow(x)-1)*x/(n-k) })
  sp = Reduce('+', sp_nonsum)

  # (i) LDA
  if(choice==1) {
    
    # Training data
    d = t(means)%*%solve(sp)%*%x + matrix(rep(diag(-(1/2)*t(means)%*%solve(sp)%*%means),each=n),ncol=n,byrow=TRUE) + matrix(rep(log(prior),each=n),ncol=n, byrow=TRUE)
    c = as.matrix(apply(d, 2, function(x) which(x==max(x))))
    # Test data
    d.t = t(means)%*%solve(sp)%*%x.t + matrix(rep(diag(-(1/2)*t(means)%*%solve(sp)%*%means),each=n.t),ncol=n.t,byrow=TRUE) + matrix(rep(log(prior),each=n.t),ncol=n.t, byrow=TRUE)
    c.t = as.matrix(apply(d, 2, function(x) which(x==max(x))))
    
    # (ii) QDA
  } else 
    if(choice==2) {

    # Training data
    d = matrix(nrow=k, ncol=n)
    for (i in 1:k) {
      d[i,] = rep(-(1/2)*log(det(sk[[i]])),n) + diag(-(1/2)*t(apply(x,2,function(x){x-means[,i]}))%*%solve(sk[[i]])%*%apply(x,2,function(x){x-means[,i]})) + rep(log(prior[i]),each=n)
    }
    c = as.matrix(apply(d, 2, function(x) which(x==max(x))))
    # Test data
    d.t = matrix(nrow=k, ncol=n.t)
    for (i in 1:k) {
      d.t[i,] = rep(-(1/2)*log(det(sk[[i]])),n.t) + diag(-(1/2)*t(apply(x.t,2,function(x){x-means[,i]}))%*%solve(sk[[i]])%*%apply(x.t,2,function(x){x-means[,i]})) + rep(log(prior[i]),each=n.t)
    }
    c.t = as.matrix(apply(d.t, 2, function(x) which(x==max(x))))
   
    # (iii) RDA
   } else 
     if(choice==3) {
    
    #Alpha & gamma selection by 0.05
    alpha = seq(0,1,0.05)
    gamma = seq(0,1,0.05)
    d_temp = matrix(nrow=k, ncol=n)
    s_rda = matrix(nrow=p, ncol=p)
    sigma = mean(diag(sp))
    result = c()

    for (a in alpha) {
      for (g in gamma) {
        for (i in 1:k) {
          s_rda = a*sk[[i]]+(1-a)*(g*sp+(1-g)*sigma*diag(p))
          d_temp[i,] = rep(-(1/2)*log(det(s_rda)),n) + diag(-(1/2)*t(apply(x,2,function(x){x-means[,i]}))%*%solve(s_rda)%*%apply(x,2,function(x){x-means[,i]})) + rep(log(prior[i]),each=n)
        }
        c_temp = as.matrix(apply(d_temp, 2, function(x) which(x==max(x))))
        #table_temp = table(y, c_temp)
        #accuracy_temp = sum(table_temp[row(table_temp)==col(table_temp)])/sum(table_temp)
        accuracy_temp = sum(c_temp==y)/n
        accuracy_rate = c(a, g, accuracy_temp)
        result <- rbind(result, accuracy_rate)
      }
    }
    
    # Optimal parameters
    optimal_loc = as.numeric(which(result[,3]==max(result[,3], na.rm = TRUE)))
    optimal = result[optimal_loc,]
    colnames(optimal) = c('alpha', 'gamma', 'accuracy rate')
    rownames(optimal) = paste(rep(1:length(optimal_loc)),'parameter')
    
    cat('Optimal parameters are given as follows.', '\n') ; print(optimal)
    
    # Training data
    a = optimal[1,1]
    g = optimal[1,2]
    d = matrix(nrow=k,ncol=n)
    s_rda_op = matrix(nrow=p, ncol=p)
    for (i in 1:k){
      s_rda_op = a*sk[[i]]+(1-a)*(g*sp+(1-g)*sigma*diag(p))
      d[i,] = rep(-(1/2)*log(det(s_rda_op)),n) + diag(-(1/2)*t(apply(x,2,function(x){x-means[,i]}))%*%solve(s_rda_op)%*%apply(x,2,function(x){x-means[,i]})) + rep(log(prior[i]),each=n)
    }
    c <- as.matrix(apply(d, 2, function(x) which(x==max(x))))
    
    # Test data
    d.t <- matrix(nrow=k, ncol=n.t)
    for (i in 1:k) {
      s_rda_op = a*sk[[i]]+(1-a)*(g*sp+(1-g)*sigma*diag(p))
      d.t[i,] = rep(-(1/2)*log(det(s_rda_op)),n.t) + diag(-(1/2)*t(apply(x.t, 2, function(x){x-means[,i]}))%*%solve(s_rda_op)%*%apply(x.t, 2, function(x){x-means[,i]})) + rep(log(prior[i]),each=n.t)
    }
    c.t <- as.matrix(apply(d.t, 2, function(x) which(x==max(x)))) 
    } else warning ('Choose 1 for LDA, 2 for QDA or 3 for RDA') 
  
  
  # Output setting

  cat('Please enter the number of the rows you can have.')
  out_num = as.numeric(readline('Enter the number : '))
  
  if (choice <= 3) {
    predict = head(cbind(c(1:n), y, c), n=out_num)
    table = table(y, c, dnn=c("Actual Class","Predicted Class"))
    accuracy = sum(diag(table))/sum(table)
    Predict.t = head(cbind(c(1:n.t),y.t,c.t),n=out_num)
    table.t = table(y.t, c.t, dnn=c("Actual Class","Predicted Class"))
    accuracy.t = sum(diag(table.t))/sum(table.t)
  
    # make output file
    outputname = readline("Write the output file name you want to save (without extension name) : ")
    outputname = paste(outputname,".txt",sep="")
    
    cat("ID, Actual class, Resub pred", "\n", "-----------------------------", "\n", file = outputname, sep="")
    write.table(predict, outputname, sep= ", ", row.names=FALSE, col.names=FALSE, append=TRUE, quote=FALSE)
    cat('(continue)','\n','\n', file = outputname, sep="", append = TRUE)
    cat('Confusion Matrix (Resubstitution)', "\n", "----------------------------------", "\n",file = outputname,sep="", append=TRUE)
    capture.output(print(table), file=outputname, append=TRUE)
    cat("\n", "Model Summary (Resubstitution)", "\n", "------------------------------", "\n",file = outputname, sep="", append=TRUE)
    cat("Overall accuracy: ", round(accuracy, 3), "\n\n",file = outputname, sep="", append=TRUE)
    cat("ID, Actual class, Test pred", "\n", "-----------------------------", "\n",file = outputname,sep="", append=TRUE)
    write.table(Predict.t, file=outputname, sep= ", ", row.names=FALSE, col.names=FALSE, append=TRUE, quote=FALSE)
    cat('(continue)',"\n",'\n', file = outputname, sep="", append = TRUE)
    cat('Confusion Matrix (Test)', "\n", "----------------------------------", "\n",file = outputname,sep="", append=TRUE)
    capture.output(print(table.t), file=outputname,append=TRUE)
    cat("\n", "Model Summary (Test)", "\n", "------------------------------", "\n",file = outputname,sep="", append=TRUE)
    cat("Overall accuracy: ", round(accuracy.t, 3), "\n" ,file = outputname,sep="", append=TRUE)
    cat("Chosen tuning parameters are\n alpha = ",a,"\n gamma = ",g,file=outputname, append=TRUE)
   
    # Plotting Test Accuracy
    if (choice==3) {
      library(rgl)
      X1 = rep(alpha,each=length(alpha))
      X2 = rep(gamma,length(gamma))
      Y  = as.vector(result[,3])
      plot3d(X1,X2,Y,type='s',size=1.5,col = 'red')
      bgplot3d({
        plot.new()
        title(main ="TEST ACCURACY" ,line = 2)
        mtext(side = 1,"X1 : Alpha,    X2 : Gamma,    Y : Test Accuracy", line = 3)
      })}
    
    cat("Output file has been saved in ",getwd(),"/",outputname,sep="")}  
  
  }



HW4 = function() {
  cat('Enter 1 to run Regression.','\n',
      'Enter 2 to run Classification.')
  ans = scan(n=1, quiet=TRUE)
  if(ans == 1){regression()} else {classification()}
}



HW4()
2
veh.dat
2
vehtest.dat
2
19
3
1/4,1/4,1/4,1/4
5
HW4KimDA_class_R_output























#####################
#### Python Code ####
#####################



import os as os
os.chdir("C:/Users/User/Desktop/18-2/DM/data")
print(os.getcwd())

### importing data function ###
def read():
    import pandas as pd
    name = input("Enter the data file name (with extension name) : ")
    fm = input("Select the data coding format(1='a b c' or 2='a,b,c'): " )
    if fm == '1':
        form = " "
    elif fm == '2':
        form = ","
    return pd.read_csv(name, sep=form, header=None)


### Regression function ###
def regression():
    
    # import packages
    import numpy as np
    import numpy.linalg as lin
    import pandas as pd
    
    # prompt user to enter the data information
    data = read()
    
    # import data
    response = data[num]
    explanatory = data.drop(num, axis=1)
    
    # design matrix
    n = data.shape[0]
    p = data.shape[1]-1
    one = pd.DataFrame(np.ones((n,1)))
    I = np.eye(n)
    X = pd.concat([pd.DataFrame(one),explanatory], axis=1)
    Y = response
    H = X.dot(lin.inv(X.T.dot(X))).dot(X.T)
    H0 = one.dot(lin.inv(one.T.dot(one))).dot(one.T)
    inv = lin.inv(X.T.dot(X))
    b = inv.dot(X.T).dot(Y).round(3)

    # multiple regression result
    yhat = H.dot(Y).round(1)
    SST = Y.T.dot(I-H0).dot(Y)
    SSE = Y.T.dot(I-H).dot(Y)
    Rsquare = round(1 - SSE/SST, 4)
    MSE = round(SSE/(n-p), 4)

    # output file name
    outputname = input("Write the output file name you want to save (without extension name) : ")
    outputname = outputname+'.txt'

    # outport the result
    with open(outputname,"w") as text_file:
        
        print("Coefficients", file=text_file)
        print("-------------", file=text_file)
        for i in range(p+1):
            if i==0:
                print("Constant:", b[i],sep="   ", file=text_file)
            else: 
                print("Beta",i,":   ",b[i],sep="", file=text_file)
        print("",file=text_file)

        print("ID, Actual values, Fitted values", file=text_file)
        print("--------------------------------", file=text_file)
        for i in range(n):
            print(i+1, Y[i], yhat[i], sep=", ", file=text_file)
        print("",file=text_file)
        
        print("Model Summary", file=text_file)
        print("-------------", file=text_file)
        print("R-square = ", Rsquare, sep="", file=text_file)
        print("MSE = ", MSE, sep="", file=text_file)

        
        
def classification() :
    # import packages
    import math
    import pandas as pd
    import numpy as np
    from numpy.linalg import inv
    from fractions import Fraction as frac
    from pandas import DataFrame as df

    # prompt user to enter the data
    print('Importing TRAINING dataset')
    train = read()
    print('Importing TEST dataset')
    test = read()
    num = int(input("Enter which column the response variable is recorded: "))-1

    # choose (i)LDA or (ii)QDA
    choice = int(input("Enter 1 to implement LDA, 2 to implement QDA or 3 to implement RDA"))

    yclass = train[num].unique()
    k = len(yclass) # Assume that values of the class variable are integers starting with 1
    print(' It has',k,'Classes.','\n', 
          'Input each priors with ascending order of Class index.','\n',
          'ex) Priors of 3 class size = 1/3, 1/3, 1/3','\n')
    prior = input('Priors : ').split(',')
    prior = list(map(lambda x: frac(x), prior))
    if not len(prior) == k :
        prior = [1/k]*k
        print("Your prior input does not correscond with class size.")
        print("So equal prior is given such as", prior)
    elif not sum(prior)==1 :
        prior = [1/k]*k
        print("Sum of your prior input is not equal to 1.")
        print("So equal prior is given such as", prior)

    # Basic vectors  
    n = train.shape[0]
    nk = train[num].groupby(train[num]).count()
    n_t = test.shape[0]
    x = train.drop(num, axis=1).T
    x_t = test.drop(num, axis=1).T
    y = train[num]
    y_t = test[num]
    c = []
    c_t = []
    p = train.shape[1]-1

    #prior = pd.DataFrame(prior)
    means = train.groupby(train[num]).mean().T
    sk = train.groupby(train[num]).cov()
    sp = 0

    for i in range(1, k+1):
        sp = sp + (nk[i]-1)*sk.loc[i]/(n-k)

    # (i) LDA
    if choice == 1 :
        # Training data
        d = (means.T).dot(inv(sp)).dot(x) + np.array(np.repeat(np.diag((-0.5)*means.T.dot(inv(sp)).dot(means)), n)).reshape(4,n) + np.repeat(np.log(prior),n).reshape(4,n) 
        c = df(d).idxmax()

         # Test data
        d_t = (means.T).dot(inv(sp)).dot(x_t) + np.array(np.repeat(np.diag((-0.5)*means.T.dot(inv(sp)).dot(means)), n_t)).reshape(4,n_t) + np.repeat(np.log(prior),n_t).reshape(4,n_t) 
        c_t = df(d_t).idxmax()

    if choice == 2 :
        # (ii) QDA
        # Training data
        d = np.zeros((k,n))
        for i in range(1, k+1):
            d[i-1] = np.repeat((-0.5)*np.log(lin.det(sk.loc[i])),n) + np.diag((-0.5)*(x.apply(lambda x : x-means[i])).T.dot(inv(sk.loc[i])).dot(x.apply(lambda x : x-means[1]))) + np.repeat(np.log(prior[i-1]),n) 
        c = df(d, index=yclass).idxmax()

        # Test data
        d_t = np.zeros((k,n_t))
        for i in range(1, k+1):
            d_t[i-1] = np.repeat((-0.5)*np.log(lin.det(sk.loc[i])),n_t) + np.diag((-0.5)*(x_t.apply(lambda x : x-means[i])).T.dot(inv(sk.loc[i])).dot(x_t.apply(lambda x : x-means[1]))) + np.repeat(np.log(prior[i-1]),n_t) 
        c_t = df(d_t, index=yclass).idxmax()

    if choice == 3 :
        #Alpha & gamma selection by 0.05
        alpha = np.arange(0, 1.05, 0.05)
        gamma = np.arange(0, 1.05, 0.05)
        d_temp = np.zeros((k, n))
        s_rda = np.zeros((p,p))
        sigma = np.diag(sp).mean()
        result = []

        for a in alpha :
            for g in gamma :
                for i in yclass :
                    s_rda = a*sk.loc[i] + (1-a)*(g*sp+(1-g)*sigma*np.eye(p))
                    d_temp[i-1] = np.repeat((-0.5)*np.log(lin.det(s_rda)),n) + np.diag((-0.5)*(x.apply(lambda x : x-means[i])).T.dot(inv(s_rda)).dot(x.apply(lambda x : x-means[i]))) + np.repeat(np.log(prior[i-1]),n) 
                c_temp = df(d_temp, index=yclass).idxmax()
                accuracy_temp = sum(c_temp==y)/n
                accuracy_rate = [a,g, accuracy_temp]
                result.append(accuracy_rate)

            result = df(result, index=range(1, len(result)+1), columns=['alpha', 'gamma', 'accuracy rate'])

        # Accuracy plot
        import matplotlib.pyplot as plt
        from mpl_toolkits.mplot3d import Axes3D
        xss, yss = np.meshgrid(alpha,gamma)
        z = np.array(result['accuracy rate'])
        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')
        ax.scatter(xss, yss, z, s=10, c='r')
        ax.set_xlabel('Alpha')
        ax.set_ylabel('Gamma')
        ax.set_zlabel('Accuracy rate')
        plt.show()

        # Optimal parameters
        optimal_loc = result['accuracy rate'].idxmax()
        optimal = df(result.loc[optimal_loc])

        print('Optimal parameters are given as follows.', '\n')
        print(optimal)
        a = int(optimal.loc['alpha'])
        g = int(optimal.loc['gamma'])

        # Training data
        d = np.zeros((k,n))
        for i in yclass :
            s_rda_op = a*sk.loc[i] + (1-a)*(g*sp + (1-g)*sigma*np.eye(p))
            d[i-1] =  np.repeat((-0.5)*np.log(lin.det(s_rda_op)),n) + np.diag((-0.5)*(x.apply(lambda x : x-means[i])).T.dot(lin.inv(s_rda_op)).dot(x.apply(lambda x : x-means[i]))) + np.repeat(np.log(prior[i-1]),n) 
        c = df(d, index=yclass).idxmax()

        # Test data
        d_t = np.zeros((k,n_t))
        for i in range(1, k+1):
            s_rda_op = a*sk.loc[i] + (1-a)*(g*sp+(1-g)*sigma*np.eye(p))
            d_t[i-1] =  np.repeat((-0.5)*np.log(lin.det(s_rda_op)),n_t) + np.diag((-0.5)*(x_t.apply(lambda x : x-means[i])).T.dot(lin.inv(s_rda_op)).dot(x_t.apply(lambda x : x-means[i]))) + np.repeat(np.log(prior[i-1]),n_t) 
        c_t = df(d_t, index=yclass).idxmax()

    # Output setting
    print('Please enter the number of the rows you can have.','\n')
    out_num = int(input('Enter the number : '))

    # Crosstable
    con = df({'Actual Class':y, 'Predicted Class':c})
    table = pd.crosstab(con['Actual Class'],con['Predicted Class'], colnames=[''])
    accuracy = np.trace(table)/n

    con_t = df({'Actual Class':y_t, 'Predicted Class':c_t})
    table_t = pd.crosstab(con_t['Actual Class'],con_t['Predicted Class'], colnames=[''])
    accuracy_t = np.trace(table_t)/n_t

    # output file
    outputname = input("Write the output file name you want to save (without extension name) : ")
    outputname = outputname+'.txt'

    with open(outputname,"w") as text_file:

        print('ID, Actual class, Resub pred', file=text_file)
        print('-----------------------------', file=text_file)
        for i in range(0, out_num):
             print(i+1, y[i], c[i], sep=', ', file=text_file)
        print('(continue)',file=text_file)        
        print('',file=text_file)
        print('Confusion Matrix (Resubstitution)', file=text_file)
        print('----------------------------------','\n','             Predicted Class', file=text_file)
        print(table, file=text_file)
        print("",file=text_file)
        print("Model Summary (Resubstitution)", file=text_file)
        print('------------------------------', file=text_file)
        print("Overall accuracy = ", accuracy.round(3), sep='', file=text_file)
        print('', file=text_file)

        print('ID, Actual class, Test pred', file=text_file)
        print('-----------------------------', file=text_file)
        for i in range(0, out_num):
            print(i+1, y_t[i], c_t[i], sep=', ', file=text_file)
        print('(continue)',file=text_file)        
        print('',file=text_file)
        print('Confusion Matrix (Test)', file=text_file)
        print('----------------------------------','\n','             Predicted Class', file=text_file)
        print(table_t, file=text_file)
        print("",file=text_file)
        print("Model Summary (Test)", file=text_file)
        print('------------------------------', file=text_file)
        print("Overall accuracy = ", accuracy_t.round(3), sep='', file=text_file)
        print('', file=text_file)